{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f767c7ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d32bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: bboxes (1, 4, 1, 4) points (1, 4, 7, 2) masks (1, 4, 256, 256)\n",
      "flags: bbox: 1 point: 15 mask: 1 examples: 4\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, json\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import resize\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Label Anything\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "sys.path.append(str(Path.cwd().parent / 'label_anything'))\n",
    "from label_anything import LabelAnything\n",
    "from label_anything.data import get_preprocessing, utils\n",
    "from label_anything.data.transforms import PromptsProcessor\n",
    "\n",
    "# ==== 定数 ====\n",
    "ANNOT_DIR = Path.cwd() / \"annotations\"\n",
    "IMAGE_DIR = Path.cwd() / \"images\"\n",
    "IMAGE_SIZE = 1024\n",
    "MASK_SIDE = 256\n",
    "CLASS_NAME_TO_ID = {\n",
    "    \"handrail\": 1, \"midrail\": 2, \"toeboard\": 3,\n",
    "    \"base_board\": 3, \"baseboard\": 3,  # COCO名の揺れ対応\n",
    "    \"手すり\": 1, \"中桟\": 2, \"巾木\": 3,\n",
    "}\n",
    "\n",
    "# ==== 可視化ユーティリティ（必要なら使用） ====\n",
    "def draw_masks(img: Image.Image, masks: torch.Tensor, colors):\n",
    "    masked_image = resize(img.copy(), MASK_SIDE)\n",
    "    for i, mask in enumerate(masks):\n",
    "        mask = mask.numpy()\n",
    "        masked_image = np.where(np.repeat(mask[:, :, np.newaxis], 3, axis=2),\n",
    "                                np.asarray(colors[i % len(colors)], dtype=\"uint8\"),\n",
    "                                masked_image)\n",
    "    masked_image = masked_image.astype(np.uint8)\n",
    "    return cv2.addWeighted(np.array(resize(img, MASK_SIDE)), 0.3, masked_image, 0.7, 0)\n",
    "\n",
    "def draw_boxes(img: Image.Image, boxes: torch.Tensor, colors):\n",
    "    img = np.array(img)\n",
    "    for i, cat in enumerate(boxes):\n",
    "        for x1,y1,x2,y2 in cat:\n",
    "            cv2.rectangle(img, (int(x1),int(y1)), (int(x2),int(y2)), colors[i % len(colors)], 2)\n",
    "    return img\n",
    "\n",
    "def draw_points(img: Image.Image, points: torch.Tensor, colors):\n",
    "    img = np.array(img)\n",
    "    for i, cat in enumerate(points):\n",
    "        for x,y in cat:\n",
    "            cv2.circle(img, (int(x),int(y)), 5, colors[i % len(colors)], -1)\n",
    "    return img\n",
    "\n",
    "def draw_all(img: Image.Image, masks, boxes, points, colors):\n",
    "    segmented_image = draw_masks(img, masks, colors)\n",
    "    img = Image.fromarray(segmented_image)\n",
    "    img = resize(img, 1024)\n",
    "    img = Image.fromarray(draw_boxes(img, boxes, colors))\n",
    "    img = Image.fromarray(draw_points(img, points, colors))\n",
    "    return img\n",
    "\n",
    "def get_image(image_tensor: torch.Tensor) -> Image.Image:\n",
    "    MEAN = np.array([123.675, 116.280, 103.530]) / 255\n",
    "    STD  = np.array([58.395,  57.120,  57.375 ]) / 255\n",
    "    x = image_tensor.numpy()\n",
    "    x = (x * STD[:, None, None]) + MEAN[:, None, None]\n",
    "    x = (x * 255).astype(np.uint8)\n",
    "    return Image.fromarray(np.moveaxis(x, 0, -1))\n",
    "\n",
    "# ==== JSON ローダ（COCO / 簡易） ====\n",
    "def _mask_from_polygons(size_hw, polygons):\n",
    "    H, W = int(size_hw[0]), int(size_hw[1])\n",
    "    m = np.zeros((H, W), dtype=np.uint8)\n",
    "    for poly in polygons or []:\n",
    "        if not poly: continue\n",
    "        pts = np.array(poly, dtype=np.float32).reshape(-1, 2)\n",
    "        pts = np.round(pts).astype(np.int32)\n",
    "        cv2.fillPoly(m, [pts], 255)\n",
    "    return m\n",
    "\n",
    "def _mask_from_rle(size_hw, counts):\n",
    "    from pycocotools import mask as mask_utils  # RLEを使わないなら未インストールでも可\n",
    "    rle = {\"size\": [int(size_hw[0]), int(size_hw[1])], \"counts\": counts}\n",
    "    m = mask_utils.decode(rle)\n",
    "    if m.ndim == 3: m = m[..., 0]\n",
    "    return (m.astype(np.uint8) * 255)\n",
    "\n",
    "def load_ann_any_json(json_path: Path, expected_stem: str | None = None) -> Dict[str, Dict[int, list]]:\n",
    "    out = {\"bboxes\": {}, \"points\": {}, \"masks\": {}}\n",
    "    if not json_path.exists():\n",
    "        return out\n",
    "\n",
    "    data = json.load(open(json_path, \"r\", encoding=\"utf-8\"))\n",
    "    is_coco = all(k in data for k in (\"images\",\"categories\",\"annotations\"))\n",
    "\n",
    "    if not is_coco:\n",
    "        # 簡易形式: {'bboxes':{'1':[[x1,y1,x2,y2],...]}, 'points':{'2':[[x,y],...]}, 'masks':{'3':[entry,...]}}\n",
    "        for k in (\"bboxes\",\"points\"):\n",
    "            raw = data.get(k, {})\n",
    "            if isinstance(raw, dict):\n",
    "                for cid, arr in raw.items():\n",
    "                    try: cid = int(cid)\n",
    "                    except: continue\n",
    "                    if isinstance(arr, list):\n",
    "                        out[k].setdefault(cid, []).extend(arr)\n",
    "        raw_masks = data.get(\"masks\", {})\n",
    "        if isinstance(raw_masks, dict):\n",
    "            for cid, entries in raw_masks.items():\n",
    "                try: cid = int(cid)\n",
    "                except: continue\n",
    "                for entry in (entries or []):\n",
    "                    fmt = str(entry.get(\"format\",\"\")).lower()\n",
    "                    size = entry.get(\"size\", None)\n",
    "                    if not size: continue\n",
    "                    if fmt == \"polygons\":\n",
    "                        m = _mask_from_polygons(size, entry.get(\"polygons\", []))\n",
    "                        if (m>0).any(): out[\"masks\"].setdefault(cid, []).append(m)\n",
    "                    elif fmt == \"rle\":\n",
    "                        m = _mask_from_rle(size, entry.get(\"counts\"))\n",
    "                        if (m>0).any(): out[\"masks\"].setdefault(cid, []).append(m)\n",
    "        return out\n",
    "\n",
    "    # COCO形式\n",
    "    images = data.get(\"images\", [])\n",
    "    anns   = data.get(\"annotations\", [])\n",
    "\n",
    "    # stem一致 → 1枚のみならフォールバック → 部分一致\n",
    "    img_entry = None\n",
    "    if expected_stem is not None:\n",
    "        for im in images:\n",
    "            if Path(str(im.get(\"file_name\",\"\"))).stem == expected_stem:\n",
    "                img_entry = im; break\n",
    "    if img_entry is None and len(images)==1:\n",
    "        img_entry = images[0]\n",
    "    if img_entry is None and expected_stem is not None:\n",
    "        for im in images:\n",
    "            if expected_stem in Path(str(im.get(\"file_name\",\"\"))).stem:\n",
    "                img_entry = im; break\n",
    "    if img_entry is None:\n",
    "        return out\n",
    "\n",
    "    image_id = img_entry[\"id\"]\n",
    "    H, W = int(img_entry.get(\"height\", 0)), int(img_entry.get(\"width\", 0))\n",
    "    tanns = [a for a in anns if a.get(\"image_id\")==image_id]\n",
    "\n",
    "    def add(dic, cid, v): dic.setdefault(int(cid), []).append(v)\n",
    "\n",
    "    for a in tanns:\n",
    "        cid = int(a.get(\"category_id\"))\n",
    "\n",
    "        # bbox [x,y,w,h] → [x1,y1,x2,y2]\n",
    "        bb = a.get(\"bbox\")\n",
    "        if isinstance(bb, (list,tuple)) and len(bb)==4:\n",
    "            x,y,w,h = bb\n",
    "            x1,y1,x2,y2 = float(x), float(y), float(x)+float(w), float(y)+float(h)\n",
    "            if x2>x1 and y2>y1:\n",
    "                add(out[\"bboxes\"], cid, [x1,y1,x2,y2])\n",
    "\n",
    "        # keypoints → points（v>0のみ）\n",
    "        kps = a.get(\"keypoints\")\n",
    "        if isinstance(kps, list) and len(kps)>=3:\n",
    "            for i in range(0,len(kps),3):\n",
    "                xk, yk, v = kps[i], kps[i+1], kps[i+2]\n",
    "                if v and xk is not None and yk is not None:\n",
    "                    add(out[\"points\"], cid, [float(xk), float(yk)])\n",
    "\n",
    "        # segmentation → masks（RLE / polygons, 空配列は無視）\n",
    "        seg = a.get(\"segmentation\")\n",
    "        if seg is not None:\n",
    "            try:\n",
    "                if isinstance(seg, dict) and \"counts\" in seg and \"size\" in seg:\n",
    "                    m = _mask_from_rle(seg[\"size\"], seg[\"counts\"])\n",
    "                    if (m>0).any(): add(out[\"masks\"], cid, m)\n",
    "                elif isinstance(seg, list) and seg and isinstance(seg[0], dict) and \"counts\" in seg[0]:\n",
    "                    for r in seg:\n",
    "                        m = _mask_from_rle(r[\"size\"], r[\"counts\"])\n",
    "                        if (m>0).any(): add(out[\"masks\"], cid, m)\n",
    "                elif isinstance(seg, list) and len(seg)>0:\n",
    "                    m = _mask_from_polygons([H,W], seg)\n",
    "                    if (m>0).any(): add(out[\"masks\"], cid, m)\n",
    "            except Exception:\n",
    "                # pycocotools未インストールでRLEが来た場合などは無視（polygonsを推奨）\n",
    "                pass\n",
    "\n",
    "    # 全ゼロマスクの最終除外（保険）\n",
    "    for cid, arrs in list(out[\"masks\"].items()):\n",
    "        out[\"masks\"][cid] = [m for m in arrs if isinstance(m, np.ndarray) and (m>0).any()]\n",
    "\n",
    "    return out\n",
    "\n",
    "def union_class_ids(dicts_per_support: List[Dict[str, Dict[int, list]]]) -> List[int]:\n",
    "    s = set()\n",
    "    for d in dicts_per_support:\n",
    "        for k in (\"bboxes\",\"points\",\"masks\"):\n",
    "            s |= set(d.get(k, {}).keys())\n",
    "    return sorted(s)\n",
    "\n",
    "# ==== 小技：空マスク除外 & 重心点補完 ====\n",
    "def filter_empty_masks(masks_per_img: Dict[int, List[np.ndarray]]):\n",
    "    for cid, arrs in list(masks_per_img.items()):\n",
    "        masks_per_img[cid] = [m for m in arrs if isinstance(m, np.ndarray) and m.ndim==2 and (m>0).any()]\n",
    "\n",
    "def mask_centroid(mask: np.ndarray):\n",
    "    ys, xs = np.nonzero(mask > 0)\n",
    "    if len(xs)==0: return None\n",
    "    return int(xs.mean()), int(ys.mean())\n",
    "\n",
    "# ==== モデル/前処理 ====\n",
    "accelerator = Accelerator(cpu=True)\n",
    "device = accelerator.device\n",
    "\n",
    "la = LabelAnything.from_pretrained(\"pasqualedem/label_anything_sam_1024_coco\")\n",
    "\n",
    "img_paths = sorted(list(IMAGE_DIR.glob(\"*.jpg\")) + list(IMAGE_DIR.glob(\"*.jpeg\")) +\n",
    "                   list(IMAGE_DIR.glob(\"*.png\")) + list(IMAGE_DIR.glob(\"*.JPG\")) + list(IMAGE_DIR.glob(\"*.PNG\")))\n",
    "assert len(img_paths) >= 2, \"画像はクエリ1 + サポート1以上が必要です（./images に配置）。\"\n",
    "\n",
    "def open_rgb(p: Path) -> Image.Image:\n",
    "    return Image.open(p).convert(\"RGB\")\n",
    "\n",
    "query_orig = open_rgb(img_paths[0])\n",
    "support_orig_images = [open_rgb(p) for p in img_paths[1:]]\n",
    "\n",
    "preprocess = get_preprocessing({\"common\": {\"custom_preprocess\": True, \"image_size\": IMAGE_SIZE}})\n",
    "query_image   = preprocess(query_orig)\n",
    "support_images = [preprocess(img) for img in support_orig_images]\n",
    "\n",
    "support_sizes: List[Tuple[int,int]] = [img.size for img in support_orig_images]  # (W,H)\n",
    "all_sizes: List[Tuple[int,int]] = [query_orig.size] + support_sizes\n",
    "\n",
    "prompts_processor = PromptsProcessor(\n",
    "    long_side_length=IMAGE_SIZE, masks_side_length=MASK_SIDE, custom_preprocess=True\n",
    ")\n",
    "\n",
    "# ==== JSON → bboxes/points/masks ====\n",
    "support_annots: List[Dict[str, Dict[int, list]]] = []\n",
    "for p in img_paths[1:]:\n",
    "    ann_path = (ANNOT_DIR / f\"{p.stem}.json\").resolve()\n",
    "    support_annots.append(load_ann_any_json(ann_path, expected_stem=p.stem))\n",
    "\n",
    "cat_ids = union_class_ids(support_annots) or [1,2,3]\n",
    "cat_ids = sorted(cat_ids)\n",
    "\n",
    "bboxes_list: List[Dict[int, List[List[float]]]] = []\n",
    "points_list: List[Dict[int, List[List[float]]]] = []\n",
    "masks_list : List[Dict[int, List[np.ndarray]]] = []\n",
    "\n",
    "for ann in support_annots:\n",
    "    per_b = {cid: list(ann.get(\"bboxes\", {}).get(cid, [])) for cid in cat_ids}\n",
    "    per_p = {cid: list(ann.get(\"points\", {}).get(cid, [])) for cid in cat_ids}\n",
    "    per_m = {cid: list(ann.get(\"masks\",  {}).get(cid, [])) for cid in cat_ids}\n",
    "\n",
    "    # 小技1: 空マスク除外\n",
    "    filter_empty_masks(per_m)\n",
    "\n",
    "    # 小技2: マスクがあるのにポイントが無いクラスに重心点を1つ補完\n",
    "    for cid, arrs in per_m.items():\n",
    "        if len(arrs)>0 and len(per_p.get(cid, []))==0:\n",
    "            c = mask_centroid(arrs[0])\n",
    "            if c is not None:\n",
    "                per_p.setdefault(cid, []).append(list(c))\n",
    "\n",
    "    bboxes_list.append(per_b)\n",
    "    points_list.append(per_p)\n",
    "    masks_list.append(per_m)\n",
    "\n",
    "# bbox を LA 形式に変換\n",
    "converted_bboxes: List[Dict[int, List[List[float]]]] = []\n",
    "for img_bboxes, orig_img in zip(bboxes_list, support_orig_images):\n",
    "    out = {}\n",
    "    for cid, cat_bboxes in img_bboxes.items():\n",
    "        out[cid] = [prompts_processor.convert_bbox(b, *orig_img.size, noise=False) for b in cat_bboxes]\n",
    "    converted_bboxes.append(out)\n",
    "\n",
    "# 背景 -1\n",
    "bboxes_list_bg = [{**{-1: []}, **bb} for bb in converted_bboxes]\n",
    "points_list_bg = [{**{-1: []}, **pp} for pp in points_list]\n",
    "masks_list_bg  = [{**{-1: []}, **mm} for mm in masks_list]\n",
    "cat_ids_bg = [-1] + cat_ids\n",
    "\n",
    "# numpy 化（空でも配列化）\n",
    "for i in range(len(bboxes_list_bg)):\n",
    "    for cid in cat_ids_bg:\n",
    "        bboxes_list_bg[i][cid] = np.array(bboxes_list_bg[i][cid], dtype=np.float32)\n",
    "        points_list_bg[i][cid] = np.array(points_list_bg[i][cid], dtype=np.float32)\n",
    "        # masks は ndarray のリストのまま（LA側で 256 に整形）\n",
    "\n",
    "# tensor 化\n",
    "bboxes, flag_bboxes = utils.annotations_to_tensor(prompts_processor, bboxes_list_bg, support_sizes, utils.PromptType.BBOX)\n",
    "points, flag_points = utils.annotations_to_tensor(prompts_processor, points_list_bg, support_sizes, utils.PromptType.POINT)\n",
    "masks,  flag_masks  = utils.annotations_to_tensor(prompts_processor, masks_list_bg,  support_sizes, utils.PromptType.MASK)\n",
    "\n",
    "flag_examples = utils.flags_merge(flag_bboxes=flag_bboxes, flag_points=flag_points, flag_masks=flag_masks)\n",
    "\n",
    "# ==== 推論 ====\n",
    "input_dict = {\n",
    "    utils.BatchKeys.IMAGES: torch.stack([query_image] + support_images).unsqueeze(0),\n",
    "    utils.BatchKeys.PROMPT_BBOXES: bboxes.unsqueeze(0),\n",
    "    utils.BatchKeys.FLAG_BBOXES:   flag_bboxes.unsqueeze(0),\n",
    "    utils.BatchKeys.PROMPT_POINTS: points.unsqueeze(0),\n",
    "    utils.BatchKeys.FLAG_POINTS:   flag_points.unsqueeze(0),\n",
    "    utils.BatchKeys.PROMPT_MASKS:  masks.unsqueeze(0),\n",
    "    utils.BatchKeys.FLAG_MASKS:    flag_masks.unsqueeze(0),\n",
    "    utils.BatchKeys.FLAG_EXAMPLES: flag_examples.unsqueeze(0),\n",
    "    utils.BatchKeys.DIMS: torch.tensor([all_sizes], dtype=torch.int32),\n",
    "}\n",
    "def dict_to_device(d, device):\n",
    "    if isinstance(d, torch.Tensor): return d.to(device)\n",
    "    if isinstance(d, dict): return {k: dict_to_device(v, device) for k,v in d.items()}\n",
    "    if isinstance(d, list): return [dict_to_device(v, device) for v in d]\n",
    "    return d\n",
    "input_dict = dict_to_device(input_dict, device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = la(input_dict)\n",
    "logits = output[\"logits\"]\n",
    "predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "# ==== 簡易ログ ====\n",
    "print(\"shapes:\",\n",
    "      \"bboxes\", tuple(bboxes.shape),\n",
    "      \"points\", tuple(points.shape),\n",
    "      \"masks\",  tuple(masks.shape))\n",
    "print(\"flags:\",\n",
    "      \"bbox:\",  int(flag_bboxes.sum().item()),\n",
    "      \"point:\", int(flag_points.sum().item()),\n",
    "      \"mask:\",  int(flag_masks.sum().item()),\n",
    "      \"examples:\", int(flag_examples.sum().item()))\n",
    "\n",
    "# ==== 可視化（任意。colorsは任意の配列） ====\n",
    "colors = [\n",
    "    (255,255,0),(255,0,0),(0,255,0),(0,0,255),\n",
    "    (255,0,255),(0,255,255),(255,165,0)\n",
    "]\n",
    "drawn_images = [\n",
    "    draw_all(get_image(img_t), img_masks, img_bboxes, img_points, colors)\n",
    "    for img_t, img_masks, img_bboxes, img_points in zip(\n",
    "        support_images, masks, bboxes, points\n",
    "    )\n",
    "]\n",
    "# Image.fromarray(drawn_images[0]).save(\"debug_support0_overlay.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0883a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] output/query_pred_colormap.png\n",
      "[saved] output/query_pred_overlay.png\n"
     ]
    }
   ],
   "source": [
    "# ===== Save predictions to ./output =====\n",
    "out_dir = Path(\"output\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# predictions: (B, H, W) を想定（このスクリプトでは B=1）\n",
    "pred = predictions[0].detach().cpu().numpy().astype(np.int32)  # H x W\n",
    "\n",
    "# query の元画像（予測と同サイズのはず。万が一違えばリサイズ）\n",
    "qh, qw = query_orig.size[1], query_orig.size[0]  # (H,W)\n",
    "if pred.shape != (qh, qw):\n",
    "    pred = cv2.resize(pred, (qw, qh), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# インデックス → 色 のルックアップ（背景含めて len(cat_ids)+1）\n",
    "# idx=0: 背景(-1), idx=1..C: cat_ids の順\n",
    "cat_ids_with_bg = [-1] + cat_ids\n",
    "# 好きなパレットに変更可\n",
    "palette = np.array([\n",
    "    (0,0,0),       # 背景: 黒\n",
    "    (255,255,0),   # class 1\n",
    "    (255,0,0),     # class 2\n",
    "    (0,255,0),     # class 3\n",
    "    (0,0,255),\n",
    "    (255,0,255),\n",
    "    (0,255,255),\n",
    "    (255,165,0),\n",
    "    (255,192,203),\n",
    "], dtype=np.uint8)\n",
    "\n",
    "num_needed = pred.max() + 1\n",
    "if num_needed > len(palette):\n",
    "    # パレット拡張（足りない分は循環）\n",
    "    extra = np.vstack([palette[1:]] * ((num_needed // (len(palette)-1)) + 1))\n",
    "    palette = np.vstack([palette[:1], extra[:num_needed-1]])\n",
    "\n",
    "# カラーマップ画像（H,W,3）\n",
    "color_map = palette[np.clip(pred, 0, len(palette)-1)]\n",
    "# 保存（クラス色だけ）\n",
    "Image.fromarray(color_map).save(out_dir / \"query_pred_colormap.png\")\n",
    "\n",
    "# オーバーレイ（元画像と半透明合成）\n",
    "query_rgb = np.array(query_orig)\n",
    "overlay = cv2.addWeighted(query_rgb, 0.5, color_map, 0.5, 0.0)\n",
    "Image.fromarray(overlay).save(out_dir / \"query_pred_overlay.png\")\n",
    "\n",
    "# クラス別の2値マスク（背景はスキップ）\n",
    "for idx, cid in enumerate(cat_ids_with_bg):\n",
    "    if cid == -1:  # 背景\n",
    "        continue\n",
    "    mask_bin = (pred == idx).astype(np.uint8) * 255\n",
    "    if mask_bin.any():  # そのクラスが1ピクセルでも存在する時だけ保存\n",
    "        Image.fromarray(mask_bin).save(out_dir / f\"class_{cid}_mask.png\")\n",
    "\n",
    "print(f\"[saved] {out_dir}/query_pred_colormap.png\")\n",
    "print(f\"[saved] {out_dir}/query_pred_overlay.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe56777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23989b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "label-anything",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
