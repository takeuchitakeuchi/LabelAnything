{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c12ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c23f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "sys.path.append(str(Path.cwd().parent / 'label_anything'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9961ae32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rinotsuka/code/papers/LabelAnything/LabelAnything/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: pred_mask.png\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from label_anything import LabelAnything\n",
    "from label_anything.data import get_preprocessing, utils\n",
    "from label_anything.data.transforms import PromptsProcessor\n",
    "\n",
    "# ---- 0) 画像の指定（先頭=クエリ、次=サポート1枚） ----\n",
    "img_dir = Path(\"demo/images\")  # 変えてOK\n",
    "img_paths = sorted(list(img_dir.glob(\"*.jpg\")) + list(img_dir.glob(\"*.jpeg\")) +\n",
    "                   list(img_dir.glob(\"*.png\")) + list(img_dir.glob(\"*.JPG\")) + list(img_dir.glob(\"*.PNG\")))\n",
    "assert len(img_paths) >= 2, \"クエリ1 + サポート1 以上の画像を置いてください\"\n",
    "\n",
    "open_rgb = lambda p: Image.open(p).convert(\"RGB\")\n",
    "query_p = img_paths[0]\n",
    "support_ps = [img_paths[1]]           # 必要なら複数でもOK\n",
    "\n",
    "query_img = open_rgb(query_p)\n",
    "support_imgs = [open_rgb(p) for p in support_ps]\n",
    "\n",
    "# ---- 1) 事前学習モデルをロード（学習はしない） ----\n",
    "# 公式のプリトレ重みをそのまま使う\n",
    "la = LabelAnything.from_pretrained(\"pasqualedem/label_anything_sam_1024_coco\")  # :contentReference[oaicite:2]{index=2}\n",
    "la.eval()\n",
    "\n",
    "# ---- 2) 前処理 & プロンプト準備 ----\n",
    "image_size = 1024\n",
    "preprocess = get_preprocessing({\"common\": {\"custom_preprocess\": True, \"image_size\": image_size}})\n",
    "query_t = preprocess(query_img)\n",
    "support_t = [preprocess(im) for im in support_imgs]\n",
    "\n",
    "# COCOのクラスID: 例として person=1 を推論対象にする（dog=18 などに変えてOK）\n",
    "cat_ids = [-1, 1]  # -1 は背景\n",
    "# サポート画像上の矩形（ピクセル）。[x1,y1,x2,y2] を自分の画像に合わせて変更\n",
    "bbox_px = [50, 50, 300, 400]\n",
    "\n",
    "# 変換（サポート画像ごとに用意）\n",
    "proc = PromptsProcessor(long_side_length=image_size, masks_side_length=256, custom_preprocess=True)\n",
    "raw_bboxes = []\n",
    "for im in support_imgs:\n",
    "    raw = {-1: [], 1: []}\n",
    "    raw[1] = [proc.convert_bbox(bbox_px, *im.size, noise=False)]\n",
    "    raw_bboxes.append(raw)\n",
    "\n",
    "# numpy 化 → テンソル化\n",
    "for d in raw_bboxes:\n",
    "    for cid in cat_ids:\n",
    "        d[cid] = np.array(d[cid])\n",
    "\n",
    "bboxes, flag_bboxes = utils.annotations_to_tensor(proc, raw_bboxes,\n",
    "                                                  [im.size for im in support_imgs],\n",
    "                                                  utils.PromptType.BBOX)\n",
    "flag_examples = utils.flags_merge(flag_bboxes=flag_bboxes)\n",
    "\n",
    "# ---- 3) 入力パック → 推論 ----\n",
    "batch = {\n",
    "    utils.BatchKeys.IMAGES: torch.stack([query_t] + support_t).unsqueeze(0),  # (B=1, N=1+S, C,H,W)\n",
    "    utils.BatchKeys.PROMPT_BBOXES: bboxes.unsqueeze(0),\n",
    "    utils.BatchKeys.FLAG_BBOXES: flag_bboxes.unsqueeze(0),\n",
    "    utils.BatchKeys.FLAG_EXAMPLES: flag_examples.unsqueeze(0),\n",
    "    utils.BatchKeys.DIMS: torch.tensor([[im.size for im in [query_img] + support_imgs]]),\n",
    "}\n",
    "with torch.no_grad():\n",
    "    out = la(batch)             # 学習しない＝forwardだけ\n",
    "logits = out[\"logits\"]          # (B, Classes, h, w)\n",
    "\n",
    "# クエリ画像の解像度に合わせてアップサンプルしてから argmax\n",
    "logits_up = F.interpolate(logits, size=query_img.size[::-1], mode=\"bilinear\", align_corners=False)\n",
    "pred = logits_up.argmax(1)[0].cpu().numpy()   # (H, W) クラスマップ\n",
    "\n",
    "# ---- 4) 予測マスクを保存（ person=1 の部分だけ抽出） ----\n",
    "mask = (pred == 1).astype(np.uint8) * 255\n",
    "Image.fromarray(mask).save(\"pred_mask.png\")\n",
    "print(\"saved: pred_mask.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26b58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8809c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "label-anything",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
